{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2\n",
        "\n",
        "#Internship Report: Foundations and End-to-End Project in Machine Learning\n",
        "\n",
        "#Full Name: Saad Kabeer\n",
        "# Phone Number: 03255034664\n",
        "# Intern ID: ARCH-2505-0211"
      ],
      "metadata": {
        "id": "7zlvboXfTHUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S000cmaSxfM",
        "outputId": "d878573d-5cf1-43d6-b659-cd4a36b310af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8) (20640,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "# Load data as a pandas DataFrame\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "print(X.shape, y.shape)  # Expected output: (20640, 8) (20640,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2"
      ],
      "metadata": {
        "id": "Xg0MZ17xZBy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline # Import the Pipeline class\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "])"
      ],
      "metadata": {
        "id": "vcmn1cP-Zevu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3"
      ],
      "metadata": {
        "id": "pYjBRBIKafFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categorical_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "])\n"
      ],
      "metadata": {
        "id": "K3cDIX08ZKtK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4"
      ],
      "metadata": {
        "id": "HFaxjrYjbQzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "numeric_features = ['MedInc','HouseAge','AveRooms','AveBedrms','Population','AveOccup']\n",
        "categorical_features = ['Ocean_Proximity']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features),\n",
        "])\n"
      ],
      "metadata": {
        "id": "QtThchCdamwL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5"
      ],
      "metadata": {
        "id": "-6KPnRiNbTRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['bedrooms_per_room'] = X['AveBedrms'] / X['AveRooms']\n",
        "X['pop_per_household']  = X['Population'] / X['AveOccup']\n"
      ],
      "metadata": {
        "id": "qzPC2wLZat-e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6"
      ],
      "metadata": {
        "id": "3MgkvetobVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "reg_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])\n"
      ],
      "metadata": {
        "id": "bNx1DWVqawuH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7"
      ],
      "metadata": {
        "id": "lA8zdXgHbXxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. Create dummy data (replace with your actual data loading)\n",
        "# If you have a CSV, upload it to Colab and read it like this:\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "# X = df.drop('target_column', axis=1)\n",
        "# y = df['target_column']\n",
        "\n",
        "# For demonstration:\n",
        "np.random.seed(42)\n",
        "X = pd.DataFrame(np.random.rand(100, 10), columns=[f'feature_{i}' for i in range(10)])\n",
        "y = pd.Series(np.random.rand(100) * 100)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Define the pipeline\n",
        "reg_pipeline = Pipeline([\n",
        "    ('preprocessor', StandardScaler()), # Standardize features\n",
        "    ('regressor', RandomForestRegressor(random_state=42)) # The regressor we want to tune\n",
        "])\n",
        "\n",
        "# 3. Define the parameter grid\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [50, 100],  # Reduced for faster testing\n",
        "    'regressor__max_features': [2, 4],     # Reduced for faster testing\n",
        "    'regressor__max_depth': [None, 10]\n",
        "}\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"Checking for NaNs in X_train:\", X_train.isnull().sum().sum())\n",
        "print(\"Checking for NaNs in y_train:\", y_train.isnull().sum())\n",
        "\n",
        "# 4. Perform GridSearchCV\n",
        "print(\"Starting GridSearchCV fit...\")\n",
        "grid_search = GridSearchCV(reg_pipeline, param_grid, cv=3, # Reduced cv for faster testing\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           verbose=2, # Add verbose to see progress\n",
        "                           n_jobs=-1) # Use all available cores for faster computation\n",
        "\n",
        "try:\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"GridSearchCV fit complete.\")\n",
        "\n",
        "    # 5. Print best parameters and RMSE\n",
        "    print(\"Best params:\", grid_search.best_params_)\n",
        "    print(\"Best RMSE:\", np.sqrt(-grid_search.best_score_))\n",
        "\n",
        "    # Optional: Evaluate on test set\n",
        "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    print(\"Test RMSE:\", test_rmse)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during GridSearchCV fit: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KC7JV39ghHZ",
        "outputId": "4f55da2d-00d4-42de-e533-984d446f1288"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (80, 10)\n",
            "y_train shape: (80,)\n",
            "Checking for NaNs in X_train: 0\n",
            "Checking for NaNs in y_train: 0\n",
            "Starting GridSearchCV fit...\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "GridSearchCV fit complete.\n",
            "Best params: {'regressor__max_depth': None, 'regressor__max_features': 4, 'regressor__n_estimators': 50}\n",
            "Best RMSE: 30.58455801199237\n",
            "Test RMSE: 30.292085196424402\n"
          ]
        }
      ]
    }
  ]
}